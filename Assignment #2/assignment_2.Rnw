\documentclass[12pt]{article}
 
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb, mathtools}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{fixltx2e}
\usepackage[shortlabels]{enumitem}
\usepackage{mathrsfs}
 
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
 
\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{question}[2][Question]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newcommand{\textfrac}[2]{\dfrac{\text{#1}}{\text{#2}}}

\DeclareMathOperator{\proj}{proj}
\newcommand{\vct}{\mathbf}
\newcommand{\vctproj}[2][]{\proj_{\vct{#1}}\vct{#2}}

\begin{document}

\title{Advanced Mathematical Statistics: Assignment 2}

\author{Chris Hayduk}
\date{October 3, 2019}

\maketitle

<<echo=F, results = 'hide', warning=FALSE, message=FALSE>>=
# set the global chunk options
opts_chunk$set(message=FALSE, # don't print R messages in pdf -- CHANGE TO FALSE WHEN SUBMITTING FINAL VERSION!!!
               warning=FALSE) # don't print warnings in pdf -- CHANGE TO FALSE WHEN SUBMITTING FINAL VERSION!!!

# load .RData files, .R files, etc.
# R packages required
suppressMessages(library(tidyverse, quietly=TRUE, warn.conflicts = FALSE, verbose=FALSE))
suppressMessages(library(gridExtra, quietly=TRUE, warn.conflicts = FALSE, verbose=FALSE))
suppressMessages(library(qwraps2, quietly=TRUE, warn.conflicts = FALSE,verbose = FALSE))
suppressMessages(library(broom, quietly=TRUE, warn.conflicts = FALSE,verbose = FALSE))
suppressMessages(library(latex2exp, quietly=TRUE, warn.conflicts = FALSE,verbose = FALSE))
suppressMessages(library(mvtnorm, quietly=TRUE, warn.conflicts = FALSE,verbose = FALSE))
suppressMessages(library(scatterplot3d, quietly=TRUE, warn.conflicts = FALSE,verbose = FALSE))
@


\begin{problem}{4.2}
\end{problem}

\begin{enumerate}[a)]

\item $f(x_1, x_2) = \frac{1}{2\pi\sqrt{1.5}} \times \exp\{-\frac{2}{3}[\left(\frac{x_1}{\sqrt{2}}\right)^2 + \left(x_2 - 2\right)^2 - \left(\frac{x_1}{\sqrt{2}}\right)\left(x_2 - 2\right)]\}$

\item We have that $\rho_{12} = 0.5 \implies \sigma_{12} = 0.5(\sqrt{\sigma_{11}\sigma_{22}}) = 0.5(\sqrt{2})$. So,
\begin{align*}
&(\vct{x} - \vct{\mu})'\Sigma^{-1}(\vct{x} - \vct{\mu})\\
&= \begin{bmatrix} x_1 - \mu_1 & x_2 - \mu_2 \end{bmatrix} \frac{1}{\sigma_{11}\sigma_{22}-\sigma_{12}^2} \begin{bmatrix} \sigma_{22} & -\sigma_{12} \\ -\sigma_{12} & \sigma_{11} \end{bmatrix} \begin{bmatrix} x_1 - \mu_1 \\ x_2 - \mu_2 \end{bmatrix}\\
&= \begin{bmatrix} x_1 & x_2 - 2 \end{bmatrix} \frac{1}{2-(0.5\sqrt{2})^2} \begin{bmatrix} 1 & -0.5\sqrt{2} \\ -0.5\sqrt{2} & 2 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 - 2 \end{bmatrix}\\
&= \begin{bmatrix} \frac{2}{3} x_1 + (\frac{-\sqrt{2}}{3})(x_2 - 2) & (\frac{-\sqrt{2}}{3})(x_1 ) + \frac{4}{3}(x_2 - 2) \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 - 2 \end{bmatrix}\\
&= x_1\left(\frac{2}{3} x_1 + \left(\frac{-\sqrt{2}}{3}\right)(x_2 - 2)\right) + (x_2 - 2)\left(\left(\frac{-\sqrt{2}}{3}\right)x_1 + \frac{4}{3}(x_2 - 2)\right)\\
&= \frac{2}{3}x_1^2 + \left(\frac{-\sqrt{2}}{3}\right)(x_2 - 2)x_1 + (x_2 - 2)\left(\frac{-\sqrt{2}}{3}\right)x_1 + \frac{4}{3}(x_2 - 2)^2\\
&= \frac{2}{3}x_1^2 + \frac{-2\sqrt{2}(x_2x_1 - 2x_1)}{3} + \frac{4}{3}x_2^2 - \frac{16}{3}x_2 + \frac{16}{3}
\end{align*}

\item $c^2 = \chi^2_2(0.5) \approx 1.386294$. So we take 
\begin{align*}
\frac{2}{3}x_1^2 + \frac{-2\sqrt{2}(x_2x_1 - 2x_1)}{3} + \frac{4}{3}x_2^2 - \frac{16}{3}x_2 + \frac{16}{3} = 1.386294
\end{align*}
to be the surface of the ellipsoid containing 50\% of the probability. The graph for this can be seen below.

<<fig=TRUE, echo=F>>=
contour_density <- function(x_1, x_2){
  res <- (2/3)*x_1^2 + (-2*sqrt(2)*(x_2*x_1 - 2*x_1))/3 + (4/3)*x_2^2 - 16/3 * x_2 + 16/3
  return(res)
}

mat <- outer(seq(-3, 3, length=100),  
              seq(0, 4, length=100), 
              function(x,y) contour_density(x, y) )

require(reshape2)
require(tidyverse)
require(latex2exp)
mmat <- melt(mat)

mmat$Var1 <- rep((seq(-3, 3, length=100)), 100)

mmat$Var2 <- rep((seq(0, 4, length = 100)), each=100)

g <- ggplot(mmat, aes(x=Var1, y=Var2, z=value) )
g <- g+stat_contour(aes(col = ..level..), breaks=seq(1.386, 1.386, .1) )
g <- g + scale_colour_continuous(low = "#000000", high = "#000000") # make black
g <- g + xlab(TeX('$X_1$')) + ylab(TeX('$X_2$')) + ggtitle("Contour Plot Containing 50% of the Probability") +
  theme(plot.title = element_text(hjust = 0.5))
g

@
\end{enumerate}

\begin{problem}{4.3}
\end{problem}

\begin{enumerate}[a)]

\item $X_1$ and $X_2$ are not independent because $\sigma_{12} = \sigma_{21} = -2 \neq 0$.

\item $X_2$ and $X_3$ are independent because $\sigma_{23} = \sigma_{32} = 0$.

\item If we partition the covariance matrix into $(X_1, X_2)$ and $X_3$ partitions, we get
\begin{align*}
\left(\begin{array}{@{}cc|c@{}}
    1 & -2 & 0 \\
    -2 & 5 & 0 \\\hline
    0 & 0 & 2
  \end{array}\right)
\end{align*}

Thus, we can see that the two diagonal sections of the matrix have the forms $\vct{0}, \vct{0}'$. As a result, $(X_1, X_2)$ and $X_3$ are independent.

\item Let $\vct{A} = \begin{bmatrix} \frac{1}{2} & \frac{1}{2} & 0 \\ 0 & 0 & 1\end{bmatrix}$. From Result 4.3, we know $\vct{A}\vct{X}$ is distributed as $N_q(\vct{A}\vct{\mu}, \vct{A}\vct{\Sigma}\vct{A}')$ with $q = 2$ in this case.

So we have,
\begin{align*}
\vct{A}\vct{\Sigma}\vct{A}' &= \begin{bmatrix} \frac{1}{2} & \frac{1}{2} & 0 \\ 0 & 0 & 1\end{bmatrix} \begin{bmatrix} 1 & -2 & 0 \\ -2 & 5 & 0 \\ 0 & 0 & 2 \end{bmatrix} \begin{bmatrix} \frac{1}{2} & 0 \\ \frac{1}{2} & 0 \\ 0 & 1\end{bmatrix}\\
&= \begin{bmatrix} -\frac{1}{2} & \frac{3}{2} & 0 \\ 0 & 0 & 2\end{bmatrix} \begin{bmatrix} \frac{1}{2} & 0 \\ \frac{1}{2} & 0 \\ 0 & 1\end{bmatrix}\\
&= \begin{bmatrix} \frac{1}{2} & 0 \\ 0 & 2 \end{bmatrix}
\end{align*}

As can be clearly seen from the above matrix, $\vct{A}\vct{\Sigma}\vct{A}'$, the covariance between $\frac{X_1 + X_2}{2}$ and $X_3$ is 0. As a result, $\frac{X_1 + X_2}{2}$ and $X_3$ are independent.

\item Let $\vct{A} = \begin{bmatrix} 0 & 1 & 0 \\ -\frac{5}{2} & 1 & -1\end{bmatrix}$. From Result 4.3, we know $\vct{A}\vct{X}$ is distributed as $N_q(\vct{A}\vct{\mu}, \vct{A}\vct{\Sigma}\vct{A}')$ with $q = 2$ in this case.

So we have,
\begin{align*}
\vct{A}\vct{\Sigma}\vct{A}' &= \begin{bmatrix} 0 & 1 & 0 \\ -\frac{5}{2} & 1 & -1\end{bmatrix} \begin{bmatrix} 1 & -2 & 0 \\ -2 & 5 & 0 \\ 0 & 0 & 2 \end{bmatrix} \begin{bmatrix} 0 & -\frac{5}{2} \\ 1 & 1 \\ 0 & -1\end{bmatrix}\\
&= \begin{bmatrix} -2 & 5 & 0 \\ -\frac{9}{2} & 10 & -2\end{bmatrix} \begin{bmatrix} 0 & -\frac{5}{2} \\ 1 & 1 \\ 0 & -1\end{bmatrix}\\
&= \begin{bmatrix} 5 & 10 \\ 10 & \frac{93}{4} \end{bmatrix}
\end{align*}

We can see from the above matrix that the covariance between the random variables is not 0. Thus, $X_2$ and $X_2 - \frac{5}{2}X_1 - X_3$ are not independent.
\end{enumerate}

\begin{problem}{4.4}
\end{problem}

\begin{enumerate}[a)]

\item Let $A = \begin{bmatrix} 3 & -2 & 1 \end{bmatrix}$. By Result 4.3, $3X_1 - 2X_2 + X_3$ is distributed as $N_1(\vct{A}\vct{\mu}, \vct{A}\vct{\Sigma}\vct{A}')$ with mean vector and covariance matrix,
\begin{align*}
&\vct{A}\vct{\mu} = 6 + 6 + 1 = 13\\
&\vct{A}\vct{\Sigma}\vct{A}' = \begin{bmatrix} 2 & -1 & 1 \end{bmatrix}\vct{A}' = 6 + 2 + 1 = 9
\end{align*}

\item Let $A = \begin{bmatrix} 0 & 1 & 0 \\ -a_1 & 1 & -a_2 \end{bmatrix}$.\\

Now find $\vct{A}\vct{\Sigma}\vct{A}'$:
\begin{align*}
\vct{A}\vct{\Sigma}\vct{A}' &= \begin{bmatrix} 1 & 3 & 2 \\ -a_1 + 1 - a_2 & -a_1 + 3 - 2a_2 & a_1 + 2 - 2a_2 \end{bmatrix}\begin{bmatrix} 0 & -a_1 \\ 1 & 1 \\ 0 & -a_2 \end{bmatrix}\\
&= \begin{bmatrix} 3 & -a_1 + 3 - 2a_2 \\ -a_1 + 3 - 2a_2 & (-a_1)^2 - 2a_1 - 2a_1a_2 + 3 - 4a_2 + 2(-a_2)^2  \end{bmatrix}
\end{align*}

In order for the covariance to be 0 (ie. $X_2$ and $-a_1X_1 + X_2 - a_3X_3$ independent), we need $-a_1 + 3 - 2a_2 = 0$. That is, $a_1 + 2a_2 = 3$. For instance, take $a_1 = 1$ and $a_2 = 1$. Then we have,
\begin{align*}
\vct{A}\vct{\Sigma}\vct{A}' = \begin{bmatrix} 3 & 0 \\ 0 & -2 \end{bmatrix}
\end{align*}
\end{enumerate}

Thus, if $\vct{a} = \begin{bmatrix} a_1 \\ a_2 \end{bmatrix} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$, then we have that $X_2$ and $X_2 - \vct{a}'\begin{bmatrix} X_1 \\ X_3 \end{bmatrix}$ are independent.

\begin{problem}{4.5}
\end{problem}

\begin{enumerate}[a)]

\item

\item

\item

\end{enumerate}

\begin{problem}{4.6}
\end{problem}

\begin{problem}{4.7}
\end{problem}

\begin{problem}{4.10}
\end{problem}

\begin{problem}{4.11}
\end{problem}

\begin{problem}{4.12}
\end{problem}

\begin{problem}{4.13}
\end{problem}

\begin{problem}{4.14}
\end{problem}

\begin{problem}{4.15}
\end{problem}

\begin{problem}{4.16}
\end{problem}

\begin{problem}{4.17}
\end{problem}

\begin{problem}{4.18}
\end{problem}

\begin{problem}{4.19}
\end{problem}

\begin{problem}{4.20}
\end{problem}

\begin{problem}{4.21}
\end{problem}

\end{document}