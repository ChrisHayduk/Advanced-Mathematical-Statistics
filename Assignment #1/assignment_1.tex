\documentclass[12pt]{article}
 
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb, mathtools}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{fixltx2e}
\usepackage[shortlabels]{enumitem}
\usepackage{mathrsfs}
 
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
 
\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{question}[2][Question]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newcommand{\textfrac}[2]{\dfrac{\text{#1}}{\text{#2}}}

\DeclareMathOperator{\proj}{proj}
\newcommand{\vct}{\mathbf}
\newcommand{\vctproj}[2][]{\proj_{\vct{#1}}\vct{#2}}

\begin{document}

\title{Advanced Mathematical Statistics: Assignment 1}

\author{Chris Hayduk}
\date{September 19, 2019}

\maketitle

\begin{problem}{3.4}
\end{problem}

\begin{enumerate}[label=\alph*)]
	\item $\vct{y}_1 = \begin{bmatrix}
           3.497900 \\
           2.485475 \\
           1.782875 \\
           1.725450 \\
           1.645575 \\
           1.469800
         \end{bmatrix}$\\
         
         Then we have,
         \begin{align*}
         	\vctproj[1]{y_1} &= \frac{\vct{y'_1}\vct{1}}{\vct{1}'\vct{1}}\vct{1}\\
         	&= \frac{12.607075}{6}\vct{1}\\
         	&= (2.10117917)\vct{1}\\
         	&= \begin{bmatrix}
           2.10117917 \\
           2.10117917 \\
           2.10117917 \\
           2.10117917 \\
           2.10117917 \\
           2.10117917
         \end{bmatrix}
         \end{align*}
         
	\item We have $\overline{x}_1 = \frac{1}{6}(\sum_{i = 1}^{6} x_{1_i}) = 2.10117917$\\
	
		 Thus,
		  \begin{align*}
			\vct{d}_1 = \vct{y}_1 - \overline{x}_1\vct{1} &= \vct{y}_1 - (2.10117917)\vct{1}\\
			&= \begin{bmatrix}
           1.39672083 \\
           0.38429583 \\
           -0.31830417 \\
           -0.37572917 \\
           -0.45560417 \\
           -0.63137917
           \end{bmatrix}
		  \end{align*}
		  
		Furthermore, $L_{\vct{d}_1} = \sqrt{\vct{d}'_1\vct{d}_1} = 1.7167461$\\
		
		The sample standard deviation is given by 
		\begin{align*}
		\sqrt{\frac{1}{6} \sum_{i = 1}^{6} (y_{1_i} - \overline{x}_1)^2} &= \sqrt{\frac{1}{6} \vct{d}'_1\vct{d}_1}\\
		&= \frac{1}{\sqrt{6}} \sqrt{\vct{d}'_1\vct{d}_1}\\
		&= \frac{1}{\sqrt{6}} L_{\vct{d}_1}\\
		&= \frac{1}{\sqrt{6}}(1.7167461)\\
		&\approx 0.70085866
		\end{align*}
		
		Thus, the sample standard deviation of $\vct{y}_1$ is given by $\frac{1}{\sqrt{6}} L_{\vct{d}_1}$.
	
	\item $L_{\vct{y}_1 - \overline{x}_1\vct{1}} = L_{\vct{d}_1} = \sqrt{\vct{d}'_1\vct{d}_1} = 1.7167461$\\
	
	$L_{\vct{y}_1} = \sqrt{\vct{y}'_1\vct{y}_1} = 5.425582$
	
	$L_{\overline{x}_1\vct{1}} = \sqrt{\overline{x}_1\vct{1}'\overline{x}_1\vct{1}} = 5.14681682$
	
	\item $\vct{y}_2 = \begin{bmatrix}
           0.623 \\
           0.593 \\
           0.512 \\
           0.500 \\
           0.463 \\
           0.395
         \end{bmatrix}$\\
         
         Then we have,
         \begin{align*}
         	\vctproj[1]{y_2} &= \frac{\vct{y'_2}\vct{1}}{\vct{1}'\vct{1}}\vct{1}\\
         	&= \frac{3.086}{6}\vct{1}\\
         	&= (0.51433)\vct{1}\\
         	&= \begin{bmatrix}
           0.51433 \\
           0.51433 \\
           0.51433 \\
           0.51433 \\
           0.51433 \\
           0.51433
         \end{bmatrix}
         \end{align*}
         
         We have $\overline{x}_2 = \frac{1}{6}(\sum_{i = 1}^{6} x_{2_i}) = 0.51433$\\
         
         Thus,
		  \begin{align*}
			\vct{d}_2 = \vct{y}_2 - \overline{x}_2\vct{1} &= \vct{y}_2 - (0.51433)\vct{1}\\
			&= \begin{bmatrix}
           0.10867 \\
           0.07867 \\
           -0.00233 \\
           -0.01433 \\
           -0.05133 \\
           -0.11933
           \end{bmatrix}
		  \end{align*}
		  
		  Furthermore, $L_{\vct{d}_2} = \sqrt{\vct{d}'_2\vct{d}_2} = 0.187305$\\
		  
		The sample standard deviation is given by 
		\begin{align*}
		\sqrt{\frac{1}{6} \sum_{i = 1}^{6} (y_{2_i} - \overline{x}_2)^2} &= \sqrt{\frac{1}{6} \vct{d}'_2\vct{d}_2}\\
		&= \frac{1}{\sqrt{6}} \sqrt{\vct{d}'_2\vct{d}_2}\\
		&= \frac{1}{\sqrt{6}} L_{\vct{d}_2}\\
		&= \frac{1}{\sqrt{6}}(0.187305)\\
		&\approx 0.0764671
		\end{align*}
		
		Thus, the sample standard deviation of $\vct{y}_2$ is given by $\frac{1}{\sqrt{6}} L_{\vct{d}_2}$.
		
		$L_{\vct{y}_2 - \overline{x}_2\vct{1}} = L_{\vct{d}_2} = \sqrt{\vct{d}'_2\vct{d}_2} = 0.187305$\\
	
		$L_{\vct{y}_2} = \sqrt{\vct{y}'_2\vct{y}_2} = 1.27370$
	
		$L_{\overline{x}_2\vct{1}} = \sqrt{\overline{x}_2\vct{1}'\overline{x}_2\vct{1}} = 1.25985$
	
	\item $\cos{\theta} = \frac{\vct{d}'_1\vct{d}_2}{L_{\vct{d}_1}L_{\vct{d}_2}} = \frac{0.28686869}{1.7167461(0.187305)} \approx 0.89212910878$\\
	
	$\implies \theta = \arccos(0.89212910878) \approx 0.4687601612$

\end{enumerate}

\begin{problem}{3.7}
\end{problem}

\begin{problem}{3.8a}
\end{problem}

Total sample variance of $\vct{S}_1 = 1 + 1 + 1 = 3$.\\

Total sample variance of $\vct{S}_2 = 1 + 1 + 1 = 3$.\\

Although these matrices have very different entries in their off-diagonal elements, their total sample variances are still identical.

\begin{problem}{3.11}
\end{problem}

$\vct{S} = \begin{bmatrix}
    252.04       & -68.43 \\
    -68.43       & 123.67 \\
\end{bmatrix}$\\

Then $\vct{D}^{-1/2} = \begin{bmatrix}
    0.0629891       & 0 \\
    0       & 0.0899224 \\
\end{bmatrix}$\\

This yields,
\begin{align*}
&\vct{D}^{-1/2}\vct{S} = \begin{bmatrix}
   15.875772764       & -4.310344113 \\
    -6.15338932       & 11.120703208 \\
\end{bmatrix}\\
\implies &\vct{D}^{-1/2}\vct{S}\vct{D}^{-1/2} = \begin{bmatrix}
   1.000000638       & -0.3875965 \\
    -0.3875965       & 1.0000322 \\
\end{bmatrix} = \vct{R}
\end{align*}

Now define $\vct{D}^{1/2} = \begin{bmatrix}
    15.8758       & 0 \\
    0       & 11.1207 \\
\end{bmatrix}$\\

This yields,
\begin{align*}
&\vct{D}^{1/2}\vct{R} = \begin{bmatrix}
   15.875772764       & -6.153404 \\
    -4.310344113       & 11.120703208 \\
\end{bmatrix}\\
\implies &\vct{D}^{1/2}\vct{R}\vct{D}^{1/2} = \begin{bmatrix}
   252.04119       & -68.43016 \\
    -68.43106      & 123.67001 \\
\end{bmatrix} = \vct{S}
\end{align*}

\begin{problem}{3.12}
\end{problem}

\begin{align*}
&\vct{S} = \vct{D}^{1/2}\vct{R}\vct{D}^{1/2}\\
\implies &|\vct{S}| = |\vct{D}^{1/2}||\vct{R}||\vct{D}^{1/2}|\\
\implies &|\vct{S}| = \left(\prod_{i = 1}^p \sqrt{s_{ii}}\right)|\vct{R}|\left(\prod_{i = 1}^p \sqrt{s_{ii}}\right)\\
\implies &|\vct{S}| = \left(\prod_{i = 1}^p s_{ii}\right)|\vct{R}|\\
\implies &|\vct{S}| = \left(s_{11}s_{22}\cdots s_{pp}\right)|\vct{R}|\\
\end{align*}

\begin{problem}{3.13}
\end{problem}

The standardized variables (with mean 0 and standard deviation 1) yield the following covariance,
\begin{align*}
s_{ik} &= \frac{1}{n} \sum_{j=1}^n \left(\frac{x_{ji} - \overline{x}_i}{\sqrt{s_{ii}}} - \overline{x}_i\right)\left(\frac{x_{jk} - \overline{x}_k}{\sqrt{s_{kk}}} - \overline{x}_k\right)\\
&= \frac{1}{n} \sum_{j=1}^n \left(\frac{x_{ji} - \overline{x}_i}{\sqrt{s_{ii}}}\right)\left(\frac{x_{jk} - \overline{x}_k}{\sqrt{s_{kk}}}\right)\\
&= \frac{1}{n} \frac{\sum_{j=1}^n \left(x_{ji} - \overline{x}_i\right)\left(x_{jk} - \overline{x}_k\right)}{\sqrt{s_{ii}}\sqrt{s_{kk}}}\\
&= \frac{\sum_{j=1}^n \left(x_{ji} - \overline{x}_i\right)\left(x_{jk} - \overline{x}_k\right)}{\sqrt{\sum_{j=1}^n \left(x_{ji} - \overline{x}_i\right)^2}\sqrt{\sum_{j=1}^n \left(x_{jk} - \overline{x}_k\right)}} = r_{ik}
\end{align*}

Thus, $s_{ik} = r_{ik}$.

\begin{problem}{3.14}
\end{problem}

\begin{enumerate}[label=\alph*)]
	\item $\vct{c'X} = \begin{bmatrix}
           -7 \\
           1 \\
           3 \\
         \end{bmatrix}$\\
         
         Sample mean of $\vct{c'X} = \frac{-7 + 1 + 3}{3} = -1$\\
         
         Sample variance of $\vct{c'X} = \frac{(-7 - (-1))^2 + (1 - (-1))^2 + (3 - (-1))^2}{3-1} = 28$.\\
         
         $\vct{b'X} = \begin{bmatrix}
           21 \\
           19 \\
           8 \\
         \end{bmatrix}$\\
         
         Sample mean of $\vct{b'X} = \frac{21 + 19 + 8}{3} = 16$\\
         
         Sample variance of $\vct{b'X} = \frac{(21 - 16)^2 + (19 - 16)^2 + (8 - 16)^2}{3-1} = 49$.\\
         
         The sample covariance is $\frac{(-7 - (-1))(21 - 16) + (1 - (-1))(19 - 16)+ (3 - (-1))(8 - 16)}{3-1} = -28$
         
	\item Now, from the original data matrix, we get $\overline{\vct{x}} = \begin{bmatrix}
           5 \\
           2
         \end{bmatrix}$ and $\vct{S} = \begin{bmatrix}
           16 & -2\\
           -2 & 1
         \end{bmatrix}$\\
         
         Sample mean of $\vct{c'X} = \vct{c'\overline{x}} = \begin{bmatrix}
           -1 & 2
         \end{bmatrix} \begin{bmatrix}
           5 \\
           2
         \end{bmatrix} = -1$
         
         Sample mean of $\vct{b'X} = \vct{b'\overline{x}} = \begin{bmatrix}
           2 & 3
         \end{bmatrix} \begin{bmatrix}
           5 \\
           2
         \end{bmatrix} = 16$
         
         Sample variance of $\vct{c'X} = \vct{c'Sc} = \begin{bmatrix}
           -1 & 2
         \end{bmatrix} \begin{bmatrix}
           16 & -2\\
           -2 & 1
         \end{bmatrix} \begin{bmatrix}
           -1 \\
            2
         \end{bmatrix} = 28$
         
         Sample variance of $\vct{b'X} = \vct{b'Sb} = \begin{bmatrix}
           2 & 3
         \end{bmatrix} \begin{bmatrix}
           16 & -2\\
           -2 & 1
         \end{bmatrix} \begin{bmatrix}
           2 \\
           3
         \end{bmatrix} = 49$
         
         Sample covariance of $\vct{b'X}$ and $\vct{c'X} = \vct{b'Sc} = \begin{bmatrix}
           2 & 3
         \end{bmatrix} \begin{bmatrix}
           16 & -2\\
           -2 & 1
         \end{bmatrix} \begin{bmatrix}
           -1 \\
           2
         \end{bmatrix} = -28$  
\end{enumerate}

\begin{problem}{3.16}
\end{problem}

We have,
\begin{align*}
E(\vct{V} - \vct{\mu_V})(\vct{V} - \vct{\mu_V})' &= E(\vct{V}\vct{V}') - \vct{\mu_v}E(\vct{V}') - E(\vct{V})\vct{\mu_V}' + \vct{\mu_V}\vct{\mu_V}'\\
&= E(\vct{V}\vct{V}') - \vct{\mu_V}\vct{\mu_V}' 
\end{align*}

Thus,
\begin{align*}
E(\vct{V}\vct{V}') &= E(\vct{V} - \vct{\mu_V})(\vct{V} - \vct{\mu_V})' + \vct{\mu_V}\vct{\mu_V}' \\
&= \vct{\Sigma_V} + \vct{\mu_V}\vct{\mu_V}'
\end{align*}

\begin{problem}{3.17}
\end{problem}

We know that $P[X_1 \leq x_1, \cdots , X_p \leq x_p \; \mathrm{and} \; Z_1 \leq z_1, \cdots , Z_q \leq z_q] = P[X_1 \leq x_1, \cdots , X_p \leq x_p] \cdot P[Z_1 \leq z_1, \cdots , Z_q \leq z_q]$ by independence of $\vct{X}$ and $\vct{Z}$.\\

Fix $k \in \{1, ..., p\}$. Then, let $j$ range over $\{1, ..., q\}$. For every $a \in \{1, ..., p\}$ such that $a \neq k$ and for every $b \in \{1, ..., q\}$ such that $b \neq j$, let $x_a$ and $z_b$ tend to infinity. Then we have,
\begin{align*}
P[X_k \leq x_k \; \mathrm{and} \; Z_j \leq z_j] = P[X_k \leq x_k] \cdot P[Z_j \leq z_j] 
\end{align*}

for every $k \in \{1, ..., p\}$ and $j \in \{1, ..., q\}$. Thus, each component of $\vct{X}$ is independent of each component of $\vct{Z}$.

\begin{problem}{3.18}
\end{problem}

\begin{enumerate}[label=\alph*)]
	\item Sample mean of total energy consumption $= 0.766 + 0.508 + 0.438 + 0.161 = 1.873$.
	
	Total variance of sample $= 0.856 + 0.568 + 0.171 + 0.043 = 1.638$.
	
	\item $\overline{x}_{1-2} = \overline{x}_1 - \overline{x}_2 = 0.258$.
	
	The variance of the excess petroleum consumption over natural gas consumption is given by $\mathrm{Var}[x_1] + \mathrm{Var}[x_2] - 2\mathrm{Cov}[x_1, x_2] = 0.856 + 0.568 - 2(0.635) = 0.154$.
	
\end{enumerate}

\end{document}